{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM_Story_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnprasanth93/Machine_Learning_Projects/blob/master/BiLSTM_Story_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIqoHbLNedFX",
        "colab_type": "text"
      },
      "source": [
        " **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ-WrMF3bgwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-THSAAErICK",
        "colab_type": "text"
      },
      "source": [
        "**Load and Merge all 5 sentences column in one sentences column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL-zrSHUkmXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/ROCStories_winter2017.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k2FAq6kfs2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dccd315-347e-467c-8b7e-34ce056804fc"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXdhSyUiptSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "c36aa9b0-06ae-4d54-bf64-cea6c2d27eec"
      },
      "source": [
        "merge_df = df\n",
        "merge_df['sentences'] = merge_df['sentence1']+' '+merge_df['sentence2']+' '+merge_df['sentence3']+' '+merge_df['sentence4']+' '+merge_df['sentence5']\n",
        "merge_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storyid</th>\n",
              "      <th>storytitle</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence3</th>\n",
              "      <th>sentence4</th>\n",
              "      <th>sentence5</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd</td>\n",
              "      <td>David Drops the Weight</td>\n",
              "      <td>David noticed he had put on a lot of weight re...</td>\n",
              "      <td>He examined his habits to try and figure out t...</td>\n",
              "      <td>He realized he'd been eating too much fast foo...</td>\n",
              "      <td>He stopped going to burger places and started ...</td>\n",
              "      <td>After a few weeks, he started to feel much bet...</td>\n",
              "      <td>David noticed he had put on a lot of weight re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0beabab2-fb49-460e-a6e6-f35a202e3348</td>\n",
              "      <td>Frustration</td>\n",
              "      <td>Tom had a very short temper.</td>\n",
              "      <td>One day a guest made him very angry.</td>\n",
              "      <td>He punched a hole in the wall of his house.</td>\n",
              "      <td>Tom's guest became afraid and left quickly.</td>\n",
              "      <td>Tom sat on his couch filled with regret about ...</td>\n",
              "      <td>Tom had a very short temper. One day a guest m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87da1a22-df0b-410c-b186-439700b70ba6</td>\n",
              "      <td>Marcus Buys Khakis</td>\n",
              "      <td>Marcus needed clothing for a business casual e...</td>\n",
              "      <td>All of his clothes were either too formal or t...</td>\n",
              "      <td>He decided to buy a pair of khakis.</td>\n",
              "      <td>The pair he bought fit him perfectly.</td>\n",
              "      <td>Marcus was happy to have the right clothes for...</td>\n",
              "      <td>Marcus needed clothing for a business casual e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9</td>\n",
              "      <td>Different Opinions</td>\n",
              "      <td>Bobby thought Bill should buy a trailer and ha...</td>\n",
              "      <td>Bill thought a truck would be better for what ...</td>\n",
              "      <td>Bobby pointed out two vehicles were much more ...</td>\n",
              "      <td>Bill was set in his ways with conventional thi...</td>\n",
              "      <td>He ended up buying the truck he wanted despite...</td>\n",
              "      <td>Bobby thought Bill should buy a trailer and ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c71bb23b-7731-4233-8298-76ba6886cee1</td>\n",
              "      <td>Overcoming shortcomings</td>\n",
              "      <td>John was a pastor with a very bad memory.</td>\n",
              "      <td>He tried to memorize his sermons many days in ...</td>\n",
              "      <td>He decided to learn to sing to overcome his ha...</td>\n",
              "      <td>He then made all his sermons into music and sa...</td>\n",
              "      <td>His congregation was delighted and so was he.</td>\n",
              "      <td>John was a pastor with a very bad memory. He t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                storyid  ...                                          sentences\n",
              "0  8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd  ...  David noticed he had put on a lot of weight re...\n",
              "1  0beabab2-fb49-460e-a6e6-f35a202e3348  ...  Tom had a very short temper. One day a guest m...\n",
              "2  87da1a22-df0b-410c-b186-439700b70ba6  ...  Marcus needed clothing for a business casual e...\n",
              "3  2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9  ...  Bobby thought Bill should buy a trailer and ha...\n",
              "4  c71bb23b-7731-4233-8298-76ba6886cee1  ...  John was a pastor with a very bad memory. He t...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ-0KGUqrUnA",
        "colab_type": "text"
      },
      "source": [
        "**Finding the maximum length sentences in dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Fe5aLhvztJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "677d5c37-0e7a-4d83-e2c1-4240de353eb3"
      },
      "source": [
        "max_len_sentence = 0;\n",
        "for i in range(len(merge_df)):#this for loop running through the entire document\n",
        "  res = len(re.findall(r'\\w+', merge_df.loc[i,'sentences']))\n",
        "  if(res>max_len_sentence):\n",
        "    max_len_sentence = res\n",
        "\n",
        "print(max_len_sentence)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDXDGsZx315",
        "colab_type": "text"
      },
      "source": [
        "### **Text Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxhNyyvNt7WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(filters='#$^&*')\n",
        "sentences = []\n",
        "#here we are taking for 3000 records we can also increase the size.\n",
        "for i in merge_df.loc[0:3000,'sentences'].values: \n",
        "  corpus = i.lower().split('\\n')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  sentences.append(corpus)\n",
        "\n",
        "total_unique_words = len(tokenizer.word_index)+1\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEZjO4kkNjy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b6cd8707-276a-4caa-ac3a-3ab74ec88dc2"
      },
      "source": [
        "display(len(tokenizer.word_index),total_unique_words)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "13080"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "13081"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSCMdNHzaOdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "40e1f439-486a-4b7d-ac36-af0ab2a17dbe"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"david noticed he had put on a lot of weight recently. he examined his habits to try and figure out the reason. he realized he'd been eating too much fast food lately. he stopped going to burger places and started a vegetarian diet. after a few weeks, he started to feel much better.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9-O10ZnDfHn",
        "colab_type": "text"
      },
      "source": [
        "**Embedding each text to an integer value**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o-0UHcIZjho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = []\n",
        "for line in sentences:\n",
        "  embeddings.append(tokenizer.texts_to_sequences(line)[0])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WJfhadsXYvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "fa680479-8078-4d78-8196-2e0a5401660c"
      },
      "source": [
        "embeddings[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[394,\n",
              " 198,\n",
              " 5,\n",
              " 14,\n",
              " 94,\n",
              " 16,\n",
              " 3,\n",
              " 127,\n",
              " 10,\n",
              " 968,\n",
              " 2389,\n",
              " 5,\n",
              " 4587,\n",
              " 9,\n",
              " 6684,\n",
              " 2,\n",
              " 174,\n",
              " 6,\n",
              " 1318,\n",
              " 28,\n",
              " 1,\n",
              " 6685,\n",
              " 5,\n",
              " 115,\n",
              " 265,\n",
              " 84,\n",
              " 376,\n",
              " 176,\n",
              " 144,\n",
              " 447,\n",
              " 206,\n",
              " 2390,\n",
              " 5,\n",
              " 279,\n",
              " 81,\n",
              " 2,\n",
              " 1808,\n",
              " 3523,\n",
              " 6,\n",
              " 69,\n",
              " 3,\n",
              " 6686,\n",
              " 1423,\n",
              " 39,\n",
              " 3,\n",
              " 132,\n",
              " 3524,\n",
              " 5,\n",
              " 69,\n",
              " 2,\n",
              " 302,\n",
              " 144,\n",
              " 458]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYYE-uo8FBoR",
        "colab_type": "text"
      },
      "source": [
        "**Spliting the list into other list using n_gram_sequence(for predict the next suitable word)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2A016oLsfmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "\n",
        "for embedding in embeddings:\n",
        "  for j in range(1,len(embedding)):\n",
        "    n_gram_sequence = embedding[:j+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krWf81nesdlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2192a78-fc81-46d7-85a4-95a89c63e495"
      },
      "source": [
        "print(len(input_sequences))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "134008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h3lL_BuFIl6",
        "colab_type": "text"
      },
      "source": [
        "**Finding max len of sentence in sequence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ifXxH0scYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6b0d1a8-c303-4e40-8257-1f12178f1bd7"
      },
      "source": [
        "max =0;\n",
        "for x in embeddings:\n",
        "  if len(x) > max:\n",
        "    max = len(x)\n",
        "print(max)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVW0qwE2TnvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "de8d3662-bcff-4fbb-a49e-4b0d07e91b29"
      },
      "source": [
        "merge_df['sentences'].values.reshape(-1,1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[\"David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\"],\n",
              "       [\"Tom had a very short temper. One day a guest made him very angry. He punched a hole in the wall of his house. Tom's guest became afraid and left quickly. Tom sat on his couch filled with regret about his actions.\"],\n",
              "       ['Marcus needed clothing for a business casual event. All of his clothes were either too formal or too casual. He decided to buy a pair of khakis. The pair he bought fit him perfectly. Marcus was happy to have the right clothes for the event.'],\n",
              "       ...,\n",
              "       ['Janice was out exercising for her big soccer game. She was doing some drills with her legs. While working out and exercising she slips on the grass. She falls down and uses her wrist to break her fall. She breaks her wrist in the process and goes to the hospital.'],\n",
              "       [\"Jamie is an american girl. Jamie wants to get married to a mexican man. Her family assumes it's because the man wants a green card. Jamie insist that she is marrying him out of love. Jamie gets married and they spent the rest of their lives together.\"],\n",
              "       ['The orange fell from the tree. It hit a girl on the head. The girl looked up at the tree. Another orange fell from the tree. That orange broke her nose.']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bNPgVHFY5M",
        "colab_type": "text"
      },
      "source": [
        "**Pre Padding the values [Sequences will be padded to the length of the longest individual sequence]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ildEx8P5bbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen =max, padding='pre'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSNqWhc8g2aQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eec75ee6-f3c5-4059-f0c3-d3d14ebfda59"
      },
      "source": [
        "input_sequences.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134008, 69)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S3uPKNB6IP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = len(input_sequences)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KgV47nQfN5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d06ad29-7788-47f7-82f0-d6592179b09a"
      },
      "source": [
        "input_sequences[:,-1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  198,     5,    14, ...,    57, 13080,   659], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzgrkP_tsDeN",
        "colab_type": "text"
      },
      "source": [
        "**Generating X values and labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gHhrg3wRzDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ce61f56-d5e4-4601-f493-e7b54d439b8e"
      },
      "source": [
        "x_value = input_sequences[:,:-1]\n",
        "x_value.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134008, 68)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKgEFtk8MSRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e4fb66e-8a01-4c97-eb68-49c08aa9db27"
      },
      "source": [
        "x_value = np.array(x_value).reshape((x_value.shape[0],x_value.shape[1],1))\n",
        "x_value.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134008, 68, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty1SvCRYmzsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96461cf8-d66e-473c-9e50-55b668f7a2c4"
      },
      "source": [
        "labels =input_sequences[:,-1]\n",
        "len(labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUf7bOgAIIU-",
        "colab_type": "text"
      },
      "source": [
        "**Y values are categorical and one hot encoded**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbPvWzEZfd6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_values = tf.keras.utils.to_categorical(labels, num_classes=total_unique_words)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-3pNNFbVCrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c12e347-5b1e-4db4-8e86-0e8c5e716081"
      },
      "source": [
        "y_values.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(134008, 13081)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi0VxcPOIDKn",
        "colab_type": "text"
      },
      "source": [
        "## **Training the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYXJ1qChjVmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "def create_model():\n",
        "  #n_timesteps = 10\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(total_unique_words, 200, input_length=max-1))\n",
        "  model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(total_unique_words, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpViOrB1yEXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0c88d0f4-d517-4523-fe05-1e167482260b"
      },
      "source": [
        "model = create_model()\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 68, 200)           2616200   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 68, 300)           421200    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20400)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 13081)             266865481 \n",
            "=================================================================\n",
            "Total params: 269,902,881\n",
            "Trainable params: 269,902,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqePiiFMl3YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating early stopping callback\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(patience=4, monitor='accuracy')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scDlKuvxnAXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "c1402180-7eef-49dd-d8c5-08754fa073d9"
      },
      "source": [
        "history=model.fit(\n",
        "    x_value, y_values, \n",
        "    epochs = 100, verbose= 1,\n",
        "    batch_size=128,\n",
        "    callbacks = [early_stop]\n",
        "    )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1047/1047 [==============================] - 153s 146ms/step - loss: 6.3092 - accuracy: 0.1323\n",
            "Epoch 2/100\n",
            "1047/1047 [==============================] - 153s 147ms/step - loss: 3.5789 - accuracy: 0.3344\n",
            "Epoch 3/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 1.5892 - accuracy: 0.6285\n",
            "Epoch 4/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 1.0505 - accuracy: 0.7380\n",
            "Epoch 5/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.8903 - accuracy: 0.7726\n",
            "Epoch 6/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.7537 - accuracy: 0.8051\n",
            "Epoch 7/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.6847 - accuracy: 0.8202\n",
            "Epoch 8/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.6542 - accuracy: 0.8287\n",
            "Epoch 9/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5903 - accuracy: 0.8448\n",
            "Epoch 10/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5576 - accuracy: 0.8536\n",
            "Epoch 11/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5661 - accuracy: 0.8535\n",
            "Epoch 12/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5762 - accuracy: 0.8525\n",
            "Epoch 13/100\n",
            "1047/1047 [==============================] - 153s 147ms/step - loss: 0.5711 - accuracy: 0.8553\n",
            "Epoch 14/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5071 - accuracy: 0.8686\n",
            "Epoch 15/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5315 - accuracy: 0.8645\n",
            "Epoch 16/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5450 - accuracy: 0.8625\n",
            "Epoch 17/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5391 - accuracy: 0.8645\n",
            "Epoch 18/100\n",
            "1047/1047 [==============================] - 153s 146ms/step - loss: 0.5179 - accuracy: 0.8689\n",
            "Epoch 19/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5370 - accuracy: 0.8664\n",
            "Epoch 20/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5165 - accuracy: 0.8692\n",
            "Epoch 21/100\n",
            "1047/1047 [==============================] - 153s 146ms/step - loss: 0.4833 - accuracy: 0.8766\n",
            "Epoch 22/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5213 - accuracy: 0.8693\n",
            "Epoch 23/100\n",
            "1047/1047 [==============================] - 154s 147ms/step - loss: 0.5236 - accuracy: 0.8705\n",
            "Epoch 24/100\n",
            "1047/1047 [==============================] - 153s 147ms/step - loss: 0.5109 - accuracy: 0.8725\n",
            "Epoch 25/100\n",
            "1047/1047 [==============================] - 153s 146ms/step - loss: 0.4962 - accuracy: 0.8762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1_DZgo0mRZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyRtYAy0ipTS",
        "colab_type": "text"
      },
      "source": [
        "## Generating story with trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl2bIoxZ-bz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "edd77776-f40f-4015-b25d-72113962dcef"
      },
      "source": [
        "init_text = \"david\"\n",
        "gen_words = 40\n",
        "\n",
        "for i in range(gen_words):\n",
        "  token_list = tokenizer.texts_to_sequences([init_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen =max-1, padding='pre')\n",
        "  pred = model.predict_classes(token_list)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == pred:\n",
        "      output_word = word\n",
        "      break\n",
        "    \n",
        "  init_text += \" \"+ word\n",
        "\n",
        "print(init_text)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-258c69623765>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "david was faced a particularly difficult exam. he expected to just pass based out it. however, he saw a person carelessly showing his exam. noble david decided to not cheat. unfortunately, david did not pass this difficult exam. to be that\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwDWJol8fvrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}